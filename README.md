# ATML_GestureRecognition_CNN

======================
Project description
======================

Gesture Recognition in American Sign Language using Deep Convolution Networks.In this project, we implement a method for using deep convolutional       
networks to classify images of both the the letters and digits​ ​in​ ​American​ ​Sign​ ​Language. We have followed the paper "Using​ ​Deep​ ​Convolutional​ ​Networks​ ​for  Gesture​ ​Recognition​ ​
in​ ​American​ ​Sign​ ​Language" by Vivek​ ​Bheda​​ ​and​​ ​​N.​ ​Dianna​ ​Radpour, Department​ ​of​ ​Computer​ ​Science,​ ​Department​ ​of​ ​Linguistics State​ ​University​ ​of​ ​New​ ​York​ ​at​ ​Buffalo.  


======================
Getting the dataset
======================

"Using​ ​Deep​ ​Convolutional​ ​Networks​ ​for  Gesture​ ​Recognition​ ​in​ ​American​ ​Sign​ ​Language"
- Download dataset from the following link and unpack everything into a folder /dataset
http://www.massey.ac.nz/~albarcza/gesture_dataset2012.html

"sign language and static-gesture recognition using scikit-learn"
- Download dataset from the following link and unpack everything into a folder /dataset_2
https://medium.freecodecamp.org/weekend-projects-sign-language-and-static-gesture-recognition-using-scikit-learn-60813d600e79



======================
Folder Structure
======================

1. bin --> This folder contains all the python scripts related to the project.
2. data --> This folder contains all the data (Training, Validation & Test)
3. lib --> This folder contains external libraries (Open source APIs)
4. test --> This folder contains test scripts
5. doc --> This folder contains documents related to the project or relevant research papers used.


The script "main.py" will initiate the program.

======================
Installation Procedure
======================

To be defined.
