# ATML_GestureRecognition_CNN


## Project description

Gesture Recognition in American Sign Language using Deep Convolution Networks.In this project, we implement a method for using deep convolutional       
networks to classify images of both the the letters and digits​ ​in​ ​American​ ​Sign​ ​Language. We have followed the paper "Using​ ​Deep​ ​Convolutional​ ​Networks​ ​for  Gesture​ ​Recognition​ ​
in​ ​American​ ​Sign​ ​Language" by Vivek​ ​Bheda​​ ​and​​ ​​N.​ ​Dianna​ ​Radpour, Department​ ​of​ ​Computer​ ​Science,​ ​Department​ ​of​ ​Linguistics State​ ​University​ ​of​ ​New​ ​York​ ​at​ ​Buffalo.  

## Getting the dataset

"Using​ ​Deep​ ​Convolutional​ ​Networks​ ​for  Gesture​ ​Recognition​ ​in​ ​American​ ​Sign​ ​Language"
- Download dataset from the following link and unpack everything into a folder /dataset
http://www.massey.ac.nz/~albarcza/gesture_dataset2012.html

"sign language and static-gesture recognition using scikit-learn"
- Download dataset from the following link and unpack everything into a folder /dataset_2
https://medium.freecodecamp.org/weekend-projects-sign-language-and-static-gesture-recognition-using-scikit-learn-60813d600e79

"ASL Alphabet"
- Download dataset from the following link and unpack everything into a folder /asl_dataset
https://www.kaggle.com/grassknoted/asl-alphabet
- Delete folders 'space' and 'del' from train dataset as well as del and space test pics

## Folder Structure

1. bin --> This folder contains all the python scripts related to the project.
2. data --> This folder contains all the data (Training, Validation & Test)
3. lib --> This folder contains external libraries (Open source APIs)
4. test --> This folder contains test scripts
5. doc --> This folder contains documents related to the project or relevant research papers used.


## Installation Procedure

### Step 1:
